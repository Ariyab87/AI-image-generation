import streamlit as st
import logging
import json
from pathlib import Path
from datetime import datetime
import base64
from PIL import Image
import io
import os
import torch
from diffusers import StableDiffusionPipeline
import time
from local_llm import LocalLLM
from memory_manager import MemoryManager
logging.basicConfig(level=logging.INFO)
@st.cache_resource
def init_components():
    llm = LocalLLM()
    memory = MemoryManager()
    with st.spinner("Loading AI Image Generation Model..."):
        try:
            model_id = "runwayml/stable-diffusion-v1-5"
            if torch.backends.mps.is_available():
                device = "mps"
            elif torch.cuda.is_available():
                device = "cuda"
            else:
                device = "cpu"
            torch_dtype = torch.float16 if device != "cpu" else torch.float32
            if device == "cpu":
                st.warning("Running on CPU. Image generation will be very slow.")
            else:
                st.info(f"Using {device.upper()} device with {torch_dtype} for accelerated performance.")
            pipe = StableDiffusionPipeline.from_pretrained(
                model_id,
                torch_dtype=torch_dtype,
                safety_checker=None,
                cache_dir="model_cache",
            )
            pipe = pipe.to(device)
            pipe.enable_attention_slicing()
            st.success("✅ AI Image Generation Model Loaded!")
            return llm, memory, pipe
        except Exception as e:
            st.error(f"Error loading AI model: {str(e)}")
            st.info("Falling back to demo mode - images will be placeholders")
            return llm, memory, None
def generate_image(pipe, prompt, filename):
    try:
        if pipe is None:
            return create_demo_image(prompt, filename)
        with st.spinner("Generating image... This may take a moment."):
            start_time = time.time()
            image = pipe(
                prompt,
                num_inference_steps=20,
                guidance_scale=7.5
            ).images[0]
            end_time = time.time()
            generation_time = end_time - start_time
            st.info(f"Image generated in {generation_time:.2f} seconds.")
        img_path = Path("outputs/images") / filename
        img_path.parent.mkdir(parents=True, exist_ok=True)
        image.save(img_path)
        return img_path
    except Exception as e:
        st.error(f"Error generating image: {e}")
        return create_demo_image(prompt, filename)
def create_demo_image(prompt, filename):
    try:
        from PIL import Image, ImageDraw, ImageFont
        img = Image.new('RGB', (512, 512), color='#2E3440')
        draw = ImageDraw.Draw(img)
        try:
            font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 20)
        except:
            font = ImageFont.load_default()
        draw.text((20, 20), "AI Generated Image", fill='#88C0D0', font=font)
        words = prompt.split()
        lines = []
        current_line = []
        for word in words:
            current_line.append(word)
            if len(' '.join(current_line)) > 40:
                lines.append(' '.join(current_line[:-1]))
                current_line = [word]
        if current_line:
            lines.append(' '.join(current_line))
        y_position = 60
        for line in lines[:8]:
            draw.text((20, y_position), line, fill='#ECEFF4', font=font)
            y_position += 25
        draw.text((20, 480), "Demo Image - Generated by AI Pipeline", fill='#88C0D0', font=font)
        img_path = Path("outputs/images") / filename
        img_path.parent.mkdir(parents=True, exist_ok=True)
        img.save(img_path)
        return img_path
    except Exception as e:
        st.error(f"Error creating demo image: {e}")
        return None
def display_image_if_exists(image_path):
    if os.path.exists(image_path):
        try:
            image = Image.open(image_path)
            st.image(image, caption=f"Generated Image: {Path(image_path).name}", use_container_width=True)
            return True
        except Exception as e:
            st.error(f"Error loading image: {e}")
            return False
    else:
        st.info(f"📁 Image file not found: {image_path}")
        st.info("💡 In a real deployment, this would show the actual generated image from Openfabric")
        return False
def display_3d_model_if_exists(model_path):
    if os.path.exists(model_path):
        st.success(f"🔮 3D Model generated: {Path(model_path).name}")
        st.info(f"📁 File size: {os.path.getsize(model_path)} bytes")
        if model_path.endswith('.glb'):
            st.info("🎮 This is a GLB 3D model file that can be viewed in:")
            st.markdown("- **Web browsers** with 3D viewers")
            st.markdown("- **3D software** like Blender, Maya")
            st.markdown("- **Game engines** like Unity, Unreal")
        return True
    else:
        st.info(f"📁 3D Model file not found: {model_path}")
        st.info("💡 In a real deployment, this would show the actual 3D model from Openfabric")
        return False
def main():
    st.set_page_config(
        page_title="AI Creative Pipeline",
        page_icon="🚀",
        layout="wide"
    )
    st.title("🚀 AI Creative Pipeline")
    st.markdown("Transform your ideas into stunning 3D models with AI")
    llm, memory, pipe = init_components()
    st.sidebar.title("🎛️ Controls")
    tab1, tab2, tab3, tab4 = st.tabs(["🎨 Generate", "🖼️ Gallery", "🧠 Memory", "📊 Analytics"])
    with tab1:
        st.header("🎨 Generate 3D Model")
        user_prompt = st.text_area(
            "Enter your creative prompt:",
            placeholder="e.g., Make me a glowing dragon standing on a cliff at sunset",
            height=100
        )
        col1, col2 = st.columns(2)
        with col1:
            if st.button("🚀 Generate", type="primary"):
                if user_prompt:
                    with st.spinner("Processing your request..."):
                        try:
                            st.info("Step 1: Enhancing prompt with AI...")
                            enhanced_prompt = llm.enhance_prompt(user_prompt)
                            st.success(f"Enhanced: {enhanced_prompt}")
                            st.info("Step 2: Generating image...")
                            image_filename = f"generated_image_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                            image_path = generate_image(pipe, enhanced_prompt, image_filename)
                            if image_path:
                                st.success(f"✅ Image generated: {image_path}")
                                st.subheader("🖼️ Generated Image")
                                display_image_if_exists(str(image_path))
                            st.info("Step 3: Converting to 3D model...")
                            model_filename = f"demo_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.glb"
                            model_path = Path("outputs/models") / model_filename
                            model_path.parent.mkdir(parents=True, exist_ok=True)
                            with open(model_path, 'wb') as f:
                                f.write(b'# Demo GLB file - In real deployment, this would be a 3D model')
                            st.success(f"✅ 3D Model generated: {model_path}")
                            st.subheader("🔮 Generated 3D Model")
                            display_3d_model_if_exists(str(model_path))
                            st.info("Step 4: Storing in memory...")
                            memory_entry = {
                                'timestamp': datetime.now().isoformat(),
                                'original_prompt': user_prompt,
                                'enhanced_prompt': enhanced_prompt,
                                'image_path': str(image_path) if image_path else f"outputs/images/{image_filename}",
                                'model_path': str(model_path),
                                'session_id': 'streamlit-user'
                            }
                            success = memory.store_memory(memory_entry)
                            if success:
                                st.success("✅ Stored in memory successfully!")
                            else:
                                st.error("❌ Failed to store in memory")
                            st.balloons()
                        except Exception as e:
                            st.error(f"Error: {str(e)}")
                else:
                    st.warning("Please enter a prompt first!")
        with col2:
            st.subheader("💡 Prompt Examples")
            examples = [
                "A futuristic robot in a cyberpunk city",
                "A magical forest with floating islands",
                "A steampunk airship flying through clouds",
                "A glowing dragon standing on a cliff at sunset"
            ]
            for example in examples:
                if st.button(example, key=f"example_{example}"):
                    st.session_state.user_prompt = example
                    st.rerun()
    with tab2:
        st.header("🖼️ Gallery - Generated Outputs")
        output_dir = Path("outputs")
        if output_dir.exists():
            st.subheader("🖼️ Generated Images")
            images_dir = output_dir / "images"
            if images_dir.exists():
                image_files = list(images_dir.glob("*.png"))
                if image_files:
                    cols = st.columns(min(3, len(image_files)))
                    for i, img_path in enumerate(image_files):
                        with cols[i % 3]:
                            try:
                                image = Image.open(img_path)
                                st.image(image, caption=img_path.name, use_container_width=True)
                                st.caption(f"Size: {os.path.getsize(img_path)} bytes")
                                st.caption(f"Created: {datetime.fromtimestamp(os.path.getctime(img_path))}")
                            except Exception as e:
                                st.error(f"Error loading {img_path.name}: {e}")
                else:
                    st.info("No images found. Generate some images first!")
            else:
                st.info("Images directory not found")
            st.subheader("🔮 Generated 3D Models")
            models_dir = output_dir / "models"
            if models_dir.exists():
                model_files = list(models_dir.glob("*.glb"))
                if model_files:
                    for model_path in model_files:
                        with st.expander(f"3D Model: {model_path.name}"):
                            st.info(f"📁 File: {model_path}")
                            st.info(f"💾 Size: {os.path.getsize(model_path)} bytes")
                            st.info(f"📅 Created: {datetime.fromtimestamp(os.path.getctime(model_path))}")
                            if str(model_path).endswith('.glb'):
                                st.success("🎮 GLB 3D Model File")
                                st.markdown("**Compatible with:**")
                                st.markdown("- Web 3D viewers")
                                st.markdown("- Blender, Maya, 3ds Max")
                                st.markdown("- Unity, Unreal Engine")
                                st.markdown("- Three.js, Babylon.js")
                else:
                    st.info("No 3D models found. Generate some models first!")
            else:
                st.info("Models directory not found")
        else:
            st.info("Outputs directory not found. Generate some content first!")
    with tab3:
        st.header("🧠 Memory Browser")
        search_query = st.text_input("Search memory:", placeholder="e.g., dragon, robot, city")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("🔍 Search"):
                if search_query:
                    results = memory.search_memory(search_query)
                    st.subheader(f"Search Results for '{search_query}'")
                    if results:
                        for i, entry in enumerate(results):
                            with st.expander(f"Entry {i+1}: {entry['original_prompt'][:50]}..."):
                                st.write(f"**Original:** {entry['original_prompt']}")
                                st.write(f"**Enhanced:** {entry['enhanced_prompt']}")
                                st.write(f"**Created:** {entry['created_at']}")
                                st.write(f"**Session:** {entry['session_id']}")
                                if entry.get('image_path'):
                                    st.write(f"**Image:** {entry['image_path']}")
                                    if os.path.exists(entry['image_path']):
                                        try:
                                            image = Image.open(entry['image_path'])
                                            st.image(image, caption="Generated Image", use_container_width=True)
                                        except:
                                            st.info("Image file exists but couldn't be displayed")
                                if entry.get('model_path'):
                                    st.write(f"**3D Model:** {entry['model_path']}")
                                    if os.path.exists(entry['model_path']):
                                        st.success("✅ 3D Model file exists")
                                    else:
                                        st.info("❌ 3D Model file not found")
                    else:
                        st.info("No results found")
                else:
                    st.warning("Please enter a search query")
        with col2:
            if st.button("📋 Show All Memory"):
                all_memory = memory.get_long_term_memory(limit=20)
                st.subheader("Recent Memory Entries")
                if all_memory:
                    for i, entry in enumerate(all_memory):
                        with st.expander(f"Entry {i+1}: {entry['original_prompt'][:50]}..."):
                            st.write(f"**Original:** {entry['original_prompt']}")
                            st.write(f"**Enhanced:** {entry['enhanced_prompt']}")
                            st.write(f"**Created:** {entry['created_at']}")
                            st.write(f"**Session:** {entry['session_id']}")
                            if entry.get('image_path'):
                                image_exists = os.path.exists(entry['image_path'])
                                st.write(f"**Image:** {'✅' if image_exists else '❌'} {entry['image_path']}")
                            if entry.get('model_path'):
                                model_exists = os.path.exists(entry['model_path'])
                                st.write(f"**3D Model:** {'✅' if model_exists else '❌'} {entry['model_path']}")
                else:
                    st.info("No memory entries found")
    with tab4:
        st.header("📊 Memory Analytics")
        stats = memory.get_memory_stats()
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Entries", stats.get('total_entries', 0))
        with col2:
            st.metric("Unique Sessions", stats.get('unique_sessions', 0))
        with col3:
            st.metric("Recent (24h)", stats.get('recent_entries_24h', 0))
        with col4:
            st.metric("Active Sessions", stats.get('active_sessions', 0))
        st.subheader("📁 File Statistics")
        output_dir = Path("outputs")
        if output_dir.exists():
            images_dir = output_dir / "images"
            models_dir = output_dir / "models"
            col1, col2 = st.columns(2)
            with col1:
                if images_dir.exists():
                    image_count = len(list(images_dir.glob("*.png")))
                    st.metric("Generated Images", image_count)
                else:
                    st.metric("Generated Images", 0)
            with col2:
                if models_dir.exists():
                    model_count = len(list(models_dir.glob("*.glb")))
                    st.metric("Generated 3D Models", model_count)
                else:
                    st.metric("Generated 3D Models", 0)
        st.subheader("📈 Memory Trends")
        recent_memory = memory.get_long_term_memory(limit=50)
        if recent_memory:
            st.write("**Recent Activity Timeline:**")
            for entry in recent_memory[:10]:
                st.write(f"🕐 {entry['created_at']} - {entry['original_prompt'][:60]}...")
        else:
            st.info("No memory data available for visualization")
if __name__ == "__main__":
    main() 